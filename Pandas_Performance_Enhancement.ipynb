{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNQ4j5hTsCx2GmgTv0XfjmS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagBRT/Intro-to-Pandas/blob/master/Pandas_Performance_Enhancement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook covers some techniques for speeding up performance for large datasets (over 1 million rows)"
      ],
      "metadata": {
        "id": "NjXOZyxaLScX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/cagBRT/Intro-to-Pandas.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "metadata": {
        "id": "yrTqospYjyYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Download the dataset here:"
      ],
      "metadata": {
        "id": "RHSHl4YbdAyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://www.kaggle.com/competitions/tabular-playground-series-sep-2021/rules"
      ],
      "metadata": {
        "id": "rRoNKqi4c_lH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. It will be be in zip format. <br>\n",
        "Unzip the folder"
      ],
      "metadata": {
        "id": "PeWcWXr3dXOD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Upload using file upload:<br>\n",
        ">tabular-playground-series-sep-2021/train.csv<br>\n",
        ">tabular-playground-series-sep-2021/test.csv\n"
      ],
      "metadata": {
        "id": "DD1GcxiIdcoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Wait for the upload to finish. <br>\n",
        "This can take about 25 minutes"
      ],
      "metadata": {
        "id": "q1x8I8P-eFOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "eTCqJ5vaJLKw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use replace to replace specific values"
      ],
      "metadata": {
        "id": "CjwSsIRuf25x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "While speed is the first benefit of replace, the second is its flexibility.\n",
        "\n",
        "We can replace all question marks with NaN - an operation that would take multiple calls with index-based replacement."
      ],
      "metadata": {
        "id": "ZrZO3pH3gTsI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nested replacement helps when you only want to affect the values of specific columns. Here, we are replacing values only in education and income columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "bClxdkGpsWad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = pd.Series([1, 2, 3, 4, 5])\n",
        "s.replace(1, 5)"
      ],
      "metadata": {
        "id": "X4p2VAPcsoLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s.replace([1, 2], method='bfill')"
      ],
      "metadata": {
        "id": "GJKPX0FftDaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'A': [0, 1, 2, 3, 4],\n",
        "                   'B': [5, 6, 7, 8, 9],\n",
        "                   'C': ['a', 'b', 'c', 'd', 'e']})\n",
        "df.replace(0, 5)"
      ],
      "metadata": {
        "id": "oLY7EnPIstlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace([0, 1, 2, 3], 4)"
      ],
      "metadata": {
        "id": "cgd_M9kHswNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.replace([0, 1, 2, 3], [4, 3, 2, 1])"
      ],
      "metadata": {
        "id": "JzJXfn9Qs6HA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income = pd.read_csv(\"adult.csv\")"
      ],
      "metadata": {
        "id": "TKdc5b-ykVof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.shape"
      ],
      "metadata": {
        "id": "eZiTVHoJkiXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.columns"
      ],
      "metadata": {
        "id": "75dErAs3mfi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.isna().sum()"
      ],
      "metadata": {
        "id": "NsFqJe-wpa81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.replace(to_replace=\"?\", value=np.nan, inplace=True)"
      ],
      "metadata": {
        "id": "nln69e1tf3FH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.isna().sum()"
      ],
      "metadata": {
        "id": "zPDFsV-PgaX-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "replace allows using lists or dictionaries to change multiple values simultaneously:\n",
        "\n"
      ],
      "metadata": {
        "id": "YZ9p6K1spuMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.gender.value_counts()"
      ],
      "metadata": {
        "id": "F5KJRMS3pw9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.replace([\"Male\", \"Female\"], [\"M\", \"F\"], inplace=True)"
      ],
      "metadata": {
        "id": "mtNZSHG3puwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.gender.value_counts()"
      ],
      "metadata": {
        "id": "UTHI5T6op4jp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When replacing a list of values with another, they will have a one-to-one, index-to-index mapping."
      ],
      "metadata": {
        "id": "rIeBd8ISqCoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income[\"native-country\"].value_counts()"
      ],
      "metadata": {
        "id": "FGpGcoUhqHsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.replace({\"United States\": \"USA\", \"US\": \"USA\"}, inplace=True)"
      ],
      "metadata": {
        "id": "92z0NQpEqDWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income[\"native-country\"].value_counts()"
      ],
      "metadata": {
        "id": "hFcQFvb0qgnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.replace({\"United States\": \"USA\", \"US\": \"USA\"}, inplace=True)"
      ],
      "metadata": {
        "id": "WlBunuN7KAnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income[\"native-country\"].value_counts()"
      ],
      "metadata": {
        "id": "zLbFCnAwKB0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.education.value_counts()"
      ],
      "metadata": {
        "id": "oDhqDAWbrM72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.income.value_counts()"
      ],
      "metadata": {
        "id": "PH-60v7HrXMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.replace(\n",
        "    {\n",
        "        \"education\": {\"HS-grad\": \"High school\", \"Some-college\": \"College\", \"12th\":\"High school\"},\n",
        "        \"income\": {\"<=50K\": 0, \">50K\": 1},\n",
        "    },\n",
        "    inplace=True,\n",
        ")"
      ],
      "metadata": {
        "id": "xliYNoBzrIXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.education.value_counts()"
      ],
      "metadata": {
        "id": "JMkkB-9Hrfo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adult_income.income.value_counts()"
      ],
      "metadata": {
        "id": "q0wXfTt0rbbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iterating efficiently"
      ],
      "metadata": {
        "id": "hxFKzw79AnYC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **The golden rule for applying operations on entire columns or data frames is to never use loops**\n",
        "\n",
        "Think about arrays as vectors and the whole data frame as a matrix"
      ],
      "metadata": {
        "id": "Hqt8kzErArm3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to perform any mathematical operation on one or more columns, there is a good chance that the operation is vectorized in Pandas.\n",
        "\n",
        "For example, the built-in Python operators like +, -, *, /, ** work just like on vectors.\n",
        "\n",
        "To get a taste of vectorization, let’s perform some operations on a massive dataset. We will choose ~1M row dataset of the old Kaggle TPS September competition:"
      ],
      "metadata": {
        "id": "Pz4MBeJxBFn4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Datatable\n",
        "\n",
        "Datatable is a python library for manipulating tabular data.\n",
        "\n",
        "\n",
        "It supports out-of-memory datasets, multi-threaded data processing, and flexible API.\n",
        "\n"
      ],
      "metadata": {
        "id": "pHTyMCIeBaXo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The datatable module emphasizes speed and big data support (an area that pandas struggles with); it also has an expressive and concise syntax, which makes datatable also useful for small datasets.\n",
        "\n",
        "Note: in pandas, there are two fundamental data structures: Series and DataFrame."
      ],
      "metadata": {
        "id": "LCMT7tEzBvU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install -U pip\n",
        "!python3 -m pip install -U datatable"
      ],
      "metadata": {
        "id": "yFjmlNscEV3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datatable as dt\n",
        "\n",
        "tps = dt.fread(\"/content/train.csv\").to_pandas()\n",
        "tps.shape"
      ],
      "metadata": {
        "id": "wQtjO32XBLU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The fastest built-in iterator of Pandas is apply."
      ],
      "metadata": {
        "id": "Jueg5SOjEpdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crazy_function(col1, col2, col3):\n",
        "    return np.sqrt(col1 ** 3 + col2 ** 2 + col3 * 10)"
      ],
      "metadata": {
        "id": "a9yIo10QEm59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time the crazy_function on three columns using apply"
      ],
      "metadata": {
        "id": "NQHDZyVFE6fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time tps['f1000'] = tps.apply(lambda row: crazy_function(row['f1'], row['f56'], row['f44']), axis=1)"
      ],
      "metadata": {
        "id": "U66LUV-GEx5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Watch what happens when we pass columns as vectors rather than scalars. No need to modify the function:"
      ],
      "metadata": {
        "id": "XlwosnLUFNf_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time tps['f1001'] = crazy_function(tps['f1'], tps['f56'], tps['f44'])"
      ],
      "metadata": {
        "id": "g5XTjFfNFQP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "About 600 times faster than the fastest iterator. But we can do even better — vectorization is even faster when used on NumPy arrays:\n",
        "\n",
        "Add .values to get the underlying NumPy ndarray of Pandas Series.\n",
        "\n",
        "NumPy arrays are faster because they don't perform additional calls for indexing and data type"
      ],
      "metadata": {
        "id": "zZPYXUfKFVa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%time tps['f1001'] = crazy_function(tps['f1'].values, tps['f56'].values, tps['f44'].values)"
      ],
      "metadata": {
        "id": "5BPObwdIFXgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas has a few more tricks up its sleeve.\n",
        "\n",
        "**Fair warning, though — these won’t benefit you much unless you have upwards of +1M rows.**"
      ],
      "metadata": {
        "id": "D-OpwfZ7Fqp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "massive_df = pd.concat([tps.drop([\"f1000\", \"f1001\"], axis=1)] * 10)\n",
        "massive_df.shape"
      ],
      "metadata": {
        "id": "zt9ffxjJFs66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory_usage = massive_df.memory_usage(deep=True)\n",
        "memory_usage_in_mbs = np.sum(memory_usage / 1024 ** 2)\n",
        "memory_usage_in_mbs"
      ],
      "metadata": {
        "id": "5i-cl91MF_XQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use our crazy_function, start with NumPy vectorization as a baseline\n",
        "\n",
        "\n",
        "It takes about 0.3 seconds for a 10M row dataset"
      ],
      "metadata": {
        "id": "-47ORxvMGLss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "massive_df[\"f1001\"] = crazy_function(\n",
        "    massive_df[\"f1\"].values, massive_df[\"f56\"].values, massive_df[\"f44\"].values\n",
        ")"
      ],
      "metadata": {
        "id": "kyZ8aB1HGH5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s improve the runtime even more.\n",
        "\n",
        "The first candidate is Numba.\n",
        "\n",
        "We install it via pip (pip install numba) and import it. Then, we will decorate our crazy_function with its jit function. JIT stands for just in time, and it translates pure Python and NumPy code to native machine instructions, giving massive speed-ups."
      ],
      "metadata": {
        "id": "TT7MZqnXGb_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba"
      ],
      "metadata": {
        "id": "gS37-d5-GgvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numba\n",
        "\n",
        "@numba.jit\n",
        "def crazy_function(col1, col2, col3):\n",
        "    return (col1 ** 3 + col2 ** 2 + col3 * 10) ** 0.5"
      ],
      "metadata": {
        "id": "QwlYhSDYGn6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "massive_df[\"f1001\"] = crazy_function(massive_df[\"f1\"].values, massive_df[\"f56\"].values, massive_df[\"f44\"].values)\n"
      ],
      "metadata": {
        "id": "WqPZI6w6GwMC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We achieved about 1.5 times speed-up.\n",
        "\n",
        "**Note that Numba works best with functions that involve many native Python loops, a lot of math, and, even better, NumPy functions and arrays.**"
      ],
      "metadata": {
        "id": "5JivpTEyG44G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The eval the function of Pandas\n",
        "\n",
        "There are two versions -\n",
        "> pd.eval (higher-level)\n",
        "\n",
        "> df.eval (in the context of DataFrames).\n",
        "\n",
        "**Like Numba, you should have at least +10,000 samples in the DataFrame to see improvements. But once you do, you will see sizeable benefits in speed.**\n",
        "\n",
        "Let’s run our crazy_function in the context of df.eval:"
      ],
      "metadata": {
        "id": "emUE94VeHXMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "massive_df.eval(\"f1001 = (f1 ** 3 + f56 ** 2 + f44 * 10) ** 0.5\", inplace=True)\n"
      ],
      "metadata": {
        "id": "Vx5ma93tHI4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's not as fast as vectorization or Numba, but it has several benefits. First, you write much less code by avoiding references to the DataFrame name. Next, it significantly speeds up non-math operations on DataFrames like boolean indexing, comparisons, and many more.\n",
        "\n"
      ],
      "metadata": {
        "id": "g5kRWgWpHqT9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **When you are not doing mathematical manipulation, evaluate your statements in pd.eval.**"
      ],
      "metadata": {
        "id": "NcsWxhftHtGF"
      }
    }
  ]
}